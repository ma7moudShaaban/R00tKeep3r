import json
import textwrap
from datetime import datetime
import os
import re

class SessionManager:
    def __init__(self, json_path, log_path, report_path):
        self.json_path   = json_path
        self.log_path    = log_path
        self.report_path = report_path

        self.payload_detected = False
        self._collecting_payload = False
        self._collecting_service = False
        self._collecting_priv = False
        self.service_detected = False
        self.priv_key_mode = False
        self._payload_buf = []
        self._priv_buf = []
        self.ssh_priv_lines = []
        self._service_buf=[]

        # Dedented, clean report template
        self.template = textwrap.dedent("""\
[{timestamp}] 1. TOOL START
========================
  • Command: {command}
  • Mode:    {mode}
  • Verbose: {verbose}
                                        
                                                                       
[{timestamp_enum}] 2. ENUMERATION
========================
  • Start Time:   {enum_start_time}
  • Findings JSON: {json_path}

[{timestamp_linpeas_run}] 3. Running LinPEAS
[{timestamp_linpeas_parse}] 4. Parsing LinPEAS
                                        
                                        
[{timestamp_escalation_start}] 5. PRIVILEGE ESCALATION
==================================
  • Start Time: {escalation_start_time}

[{timestamp_suid}] 6. SUID EXPLOITATION
  • Vectors:
{suid_vectors_indented}
  • Results:
{suid_results_indented}
  • Success: {suid_success}
                                        
                            
[{timestamp_sudo}] 7. SUDO EXPLOITATION
  • Vectors:
{sudo_vectors_indented}
  • Results:
{sudo_results_indented}
  • Success: {sudo_success}
                                        
                                        
[{timestamp_kernel}] 8. KERNEL EXPLOITATION
  • CVEs:
{kernel_vectors_indented}
  • Results:
{kernel_results_indented}
  • Success: {kernel_success}
                                        

[{timestamp_cron}] 9. CRON INJECTION
  • Jobs Extracted:
{cron_paths_indented}
  • Injection Results:
{cron_results_indented}
  • Success: {cron_success}
                                        
                                      
[{timestamp_persistence}] 10. PERSISTENCE
==========================
  • Choice: {persistence_choice}

  {persistence_block}
                                        
Privilege Escalation Result: {overall_result}
---
Generated by Session Management Module
""")

    def parse_logs(self):
      entries = []
      ts_re    = re.compile(r'^(?P<ts>\d{2}:\d{2}:\d{2}) - (?:INFO|DEBUG|ERROR) - [^-]+ - (?P<msg>.*)$')
      try:
        with open(self.log_path) as f:
          for line in f:
            m = ts_re.match(line)
            if m:
              # new log entry
              entries.append({
                "timestamp":  m.group('ts'),
                "message":    m.group('msg').rstrip()
                })
            else:
              # continuation of prior message
              if entries:
                entries[-1]['message'] += "\n" + line.rstrip()

        return entries

      except FileNotFoundError:
        print(f"Log file not found: {self.log_path}")
        return entries  # Return empty list instead of None

      except Exception as e:
        print(f"Error parsing logs: {str(e)}")
        return entries  # Return empty list instead of None
        
        #     if any(level in line for level in ("INFO", "DEBUG", "ERROR")):
        #       try:
        #         ts, _, _, msg = line.split(" - ", 3)
        #         entries.append({"timestamp": ts, "message": msg.strip()})
        #       except ValueError:
        #         continue # skip malford lines  

    def extract_persistence(self, logs):
        # Initialize defaults
        root_info = {'username': None, 'password': None, 'status': 'not chosen'}
        rev_info = { 'ip': None, 'port': None, 'hidden_dir': None,
                     'payload path': None, 'payload': None,'cronjob': None,'service path': None ,'systemd': None,'status': 'not chosen' }
        ssh_info = {'private_key': None, 'public_key': None, 'status': 'not chosen'}

        root_attempted = False
        rev_attempted = False
        ssh_attempted = False

        for entry in logs:
          msg = entry['message']

          # 1) Root account

          if 'Creating hidden root account' in msg:
            root_attempted = True

          if 'Root account ' in msg and 'created successfully' in msg:
            m = re.search(r'Root account (\S+) created successfully', msg)
            if m:
              root_info.update({
                  'username': m.group(1),
                  'status': 'success'
              })

          if 'Password:'in msg:
            m = re.search(r'Password: (\S+)', msg)
            if m:
              root_info['password'] = m.group(1)




          # 2) Reverse shell

          if 'Received attacker IP:' in msg:
              m = re.search(r'Received attacker IP: (\S+)', msg)
              if m:
                  rev_info['ip'] = m.group(1)
                  rev_attempted = True
                  
    
          if 'Received attacker PORT:' in msg:
              m = re.search(r'Received attacker PORT: (\d+)', msg)
              if m:
                  rev_info['port'] = m.group(1)


          if 'Hidden Directory path:' in msg:
              m = re.search(r'Hidden Directory path:(\S+)', msg)
              if m:
                  rev_info['hidden_dir'] = m.group(1)

          # paload
          if 'Payload Path:' in msg:
              # Extract path
              path_match = re.search(r'Payload Path:\s*(\S+)', msg)
              if path_match:
                  rev_info['payload path'] = path_match.group(1)
              self._collecting_payload = True
              self._payload_buf = []
            

          elif self._collecting_payload:
              # Split multi-line messages into individual lines
              # Remove "Payload :" from any line that contains it
              cleaned_line = re.sub(r'^Payload\s*:\s*', '', msg).strip()

              self._payload_buf.append(cleaned_line)

              if 'done' in cleaned_line:
                self._payload_buf.append(cleaned_line)
                # rev_info['payload'] = '\n'.join(self._payload_buf)
                rev_info['payload'] = textwrap.indent('\n'.join(self._payload_buf), '    ')
                self._collecting_payload = False
              else:
                self._payload_buf.append(cleaned_line)
                      
          if 'Cronjob:' in msg:
            # Cronjob: ,  Service: [...] -> capture first non-empty
            m = re.search(r'Cronjob:(.*)', msg)
            if m:
              rev_info['cronjob'] = m.group(1).strip()

          # Systemd Service Path
          if 'Service Path:' in msg:
              path_match = re.search(r'Service Path:\s*(\S+)', msg)
              if path_match:
                  rev_info['service path'] = path_match.group(1)

          # Systemd Service Content
          if 'Service:' in msg and '[Unit]' in msg:
              self._collecting_service = False
              self._service_buf = []
              service_part = msg.split('Service:', 1)[1].strip()
              # self._service_buf.extend(service_part.split('\n'))
              rev_info["systemd"] = service_part

          elif self._collecting_service:
              self._service_buf.extend(msg.strip().split('\n'))
              if any('WantedBy=' in line for line in self._service_buf):
                  rev_info['systemd'] = '\n'.join(self._service_buf)
                  self._collecting_service = False  

          if 'Success: Configuring persistence mechanism' in msg:
            rev_info['status'] = 'success'


          # 3) SSH Private Key Handling
          # private key extraction
          if 'Generated SSH Private key:' in msg:
            ssh_attempted = True
            self._collecting_priv = True
            self._priv_buf = []
            key_block = msg.split('Generated SSH Private key:', 1)[1]
            lines = key_block.split('\n')
            for line in lines:
                stripped_line = line.strip()
                if '-----BEGIN RSA PRIVATE KEY-----' in stripped_line:
                  # Extract from exact marker position (handles leading/trailing content)
                  idx = stripped_line.find('-----BEGIN RSA PRIVATE KEY-----')
                  key_line = stripped_line[idx:]
                  self._priv_buf.append(key_line)
                elif '-----END RSA PRIVATE KEY-----' in stripped_line:
                  idx = stripped_line.find('-----END RSA PRIVATE KEY-----')
                  end_line = stripped_line[idx:]
                  self._priv_buf.append(end_line)
                  ssh_info['private_key'] = '\n'.join(self._priv_buf)
                  self._collecting_priv = False
                  break  # Exit loop after finding end marker
                elif self._collecting_priv:
                    self._priv_buf.append(stripped_line)


          # public key extraction
          if 'Generated SSH Public Key:' in msg:
            m = re.search(r'Generated SSH Public Key:\s*([\w+/= ]+ssh-rsa [A-Za-z0-9+/=]+)', msg, re.MULTILINE)
            if m:
              ssh_info['public_key'] = m.group(1).strip()
          
          if 'Success: Generating SSH keys' in msg:
            ssh_info['status'] = 'success'


          # status check
          if root_attempted and root_info['status'] != 'success':
            root_info['status'] = 'failed'
          
          if rev_attempted and rev_info['status'] != 'success':
            rev_info['status'] = 'failed'

          if ssh_attempted and ssh_info['status'] != 'success':
            ssh_info['status'] = 'failed'


              
        return root_info, rev_info, ssh_info

    def generate_report(self, command, mode, verbose):
        # 0) banner
        banner_path = os.path.join(os.path.dirname(__file__), "..", "banner.txt")
        banner = ""
        if os.path.isfile(banner_path):
            with open(banner_path) as bf:
                banner = bf.read().rstrip() + "\n\n"

        # 1) load JSON
        with open(self.json_path) as jf:
            data = json.load(jf)

        # 2) parse logs
        logs = self.parse_logs() or []
        



        #extractig persistence results
        p_cfg    = data.get("persistence", {})
        p_chosen = p_cfg.get("requested", False)
        root_info, rev_info, ssh_info = self.extract_persistence(logs)

        # determining if the persistence is chosen or not to add its techniques

        if p_chosen:
          persistence_block = textwrap.indent(textwrap.dedent(f"""\
10.1 Creating root account {{
  • username: {root_info.get('username','<n/a>')}
  • password: {root_info.get('password','<n/a>')}

  status:   {root_info.get('status')}
}}

10.2 Reverse shell {{

  • Attacker IP address: {rev_info.get('ip','<n/a>')}

  • Attacker Port number: {rev_info.get('port','<n/a>')}

  • Hidden Directory Path: {rev_info.get('hidden_dir','<n/a>')}

  • Payload Path: {rev_info.get('payload path','<n/a>')}

  • Payload: 
    {rev_info.get('payload','<n/a>')}


  • Cronjob: {rev_info.get('cronjob','<n/a>')}

  • Service Path: {rev_info.get('service path','<n/a>')}

  • Systemd service: 
    {rev_info.get('systemd','<n/a>')}


  status: {rev_info.get('status')}
}}

10.3 SSH key Generation {{

  • SSH private key: 
  {ssh_info.get('private_key','<n/a>')}

  • SSH public key:  {ssh_info.get('public_key','<n/a>')}

  status: {ssh_info.get('status')}
}}
          """), '  ')

        else:
            persistence_block = ""  # nothing at all


        def ts_for(substr):
            for e in logs:
                if substr in e["message"]:
                    return e["timestamp"]
            return "--:--:--"

        # 3) top-level timestamps
        ctx = {
            "timestamp":                  ts_for("Starting enumeration"),
            "command":                    command,
            "mode":                       mode,
            "verbose":                    verbose,
            "timestamp_enum":             ts_for("Starting enumeration"),
            "enum_start_time":            ts_for("Starting enumeration"),
            "json_path":                  self.json_path,
            "timestamp_linpeas_run":      ts_for("Running LinPEAS"),
            "timestamp_linpeas_parse":    ts_for("Parsing LinPEAS"),
            "timestamp_escalation_start": ts_for("privilege escalation"),
            "escalation_start_time":      ts_for("privilege escalation"),
            "timestamp_persistence":      ts_for("persistence"),
            "persistence_choice":         "Chosen" if p_chosen else "Not chosen",
            "persistence_block":          persistence_block,
        }

        # 4) enumeration vectors
        suid_vecs   = data.get("SUID", [])
        sudo_vecs   = data.get("SudoPermissions", [])
        kernel_vecs = [e["CVE"] for e in data.get("Kernel", {}).get("Exploits", [])]
        cron_jobs   = []
        for d,jobs in data.get("CronJobs", {}).items():
            for job in jobs:
                if job == ".placeholder":
                    continue
                if isinstance(job, dict):
                    cron_jobs.append(job["command"])
                else:
                    cron_jobs.append(f"{d}/{job}")

        # 5) escalation results
        esc         = data.get("escalation_attempts", {})
        # SUID and Sudo
        suid_res    = esc.get("SUID", {})
        sudo_res    = esc.get("SudoPermissions", {})

        # Kernel results 
        kernel_res = {} 
        for entry in logs:
          msg = entry["message"]

          # 2) success → win
          if m := re.search(r'Kernel exploit succeeded for\s*(CVE-\S+)', msg):
            c = m.group(1)
            kernel_res[c] = {"status": "success"}

          # 1) not available → skipped
          elif m := re.search(r'Kernel exploit not available for CVE:\s*(CVE-\S+)', msg):
            c = m.group(1)
            kernel_res[c] = {"status": "Not available - Skipped"}
          
          # 3) We tried it → mark failed, unless already successful
          
          elif m:= re.search(r'Trying kernel exploit for CVE:\s*(CVE-\S+)', msg):
            c = m.group(1)
            if kernel_res.get(c, {}).get("status") != "success":
                kernel_res[c] = {"status": "failed"}


        # Cronjobs

        # ─── ❶ Build a dict of “jobs → their cron results” ───────────────────────
        #
        # We’ll look for these patterns (order matters a bit):
        #   1) "Cron payload injection successful for <path>"
        #   2) "Extracted cron schedule: <schedule>"
        #   3) "Cronjob exploit succeeded using command: <cmd>"
        #
        cron_res = {}
        # Initialize each job with defaults (in case JSON listed a job but log never touched it)
        for job_path in cron_jobs:  # ← cron_jobs comes from JSON further down
            cron_res[job_path] = {
                "schedule": "<n/a>",
                "attempt":  "skipped",    # default to failed until we see “...successful...”
                "command":  "<n/a>"
            }

        for entry in logs:
            msg = entry["message"]

            # ── 1) “Cron payload injection successful for /path/to/whatever” ─────────
            m1 = re.search(r"Cron payload injection successful for\s+(\S+)", msg)
            if m1:
                path = m1.group(1)
                # mark this job as “attempt: success”
                if path in cron_res:
                    cron_res[path]["attempt"] = "success"

            # ── 2) “Extracted cron schedule ─────────────────────────────
            m2 = re.search(r"Extracted cron schedule:\s*(.+)", msg)
            if m2:
                sched = m2.group(1).strip()
                # If multiple jobs use the same schedule, you can store per-path.
                # But in most flows, the schedule immediately follows injection for that path.
                # We’ll do a quick heuristic: if there’s exactly one “successful” path not yet assigned,
                # assign schedule to that. Otherwise, skip.
                for p, info in cron_res.items():
                    if info["attempt"] == "success" and info["schedule"] == "<n/a>":
                        info["schedule"] = sched
                        break

            # ── 3) “Cronjob exploit succeeded using command: /bin/bash -p” ─────────────
            m3 = re.search(r"Cronjob exploit succeeded using command:\s*(.+)", msg)
            if m3:
                cmd = m3.group(1).strip()
                # assign to whichever job was marked “success” and missing a command
                for p, info in cron_res.items():
                    if info["attempt"] == "success" and info["command"] == "<n/a>":
                        info["command"] = cmd
                        break

        # ─── ❷ Convert the dict into an indented list of lines ───────────────────────
        #
        # Each entry should look like:
        #   /home/kali/Desktop/backup.sh: [
        #       schedule: */3 * * * *
        #       attempt:  success
        #       command:  /bin/bash -p
        #   ]
        #
        cron_results_lines = []
        for path, info in cron_res.items():
            if info["attempt"] != "success":
              continue
            section = textwrap.dedent(f"""\
                {path}: [
                    schedule: {info['schedule']}
                    attempt:  {info['attempt']}
                    command:  {info['command']}
                ]""")
        
            # Now indent _all_ lines by 4 spaces, so they line up under “• Injection Results:”
            cron_results_lines.extend("    " + line for line in section.splitlines())

        # If there were no cron_jobs at all, show “<none>” instead of an empty block
        if not cron_results_lines:
            cron_results_lines = ["    <none>"]



        

        # # ─── enforce first‑success skip logic ───────
        # for result_dict in (suid_res, sudo_res, kernel_res, cron_detail):
        #     seen_success = False
        #     for vector, info in result_dict.items():
        #         st = info.get("status", "").lower()

        #         if st == "success":
        #             # the first success stays success
        #             seen_success = True

        #         if seen_success:
        #             # once we've seen a success, every further vector is skipped
        #             info["status"] = "skipped"

        #         else:
        #             # anything not marked success before we see one is a failure
        #             info["status"] = "failed"


        # 6) helpers
        def indent(lines, n=4):
            pad = " " * n
            if not lines:
                return pad + "<none>"
            return "\n".join(pad + l for l in lines)

        # -- SUID: group no_gtfobins_entry --
        missing = [b for b,v in suid_res.items() if v.get("status")=="no_gtfobins_entry"]
        others  = [(b,v["status"]) for b,v in suid_res.items() if v.get("status")!="no_gtfobins_entry"]
        suid_lines = []
        if missing:
            cnt = len(missing)
            suid_lines.append(f"(no GTFOBins entry: first {cnt} candidates)")
        for b,st in others:
            suid_lines.append(f"{b}: {st}")

        # if missing:
        #     suid_lines.append("(rest of binaries are skipped)")

        # 7) three‑state result (Success / Failed / Skipped) for each vector type
        def three_state(results: dict) -> str:

          if not results:
            return "Skipped"
    
          first_val = next(iter(results.values()))
          if isinstance(first_val, dict) and "status" in first_val:
            # SUID/Sudo/Kernel/… case
            statuses = [r.get("status") for r in results.values()]
            if "success" in statuses:
                return "Success"
            if any(s in ("failed", "timeout", "error", "no_gtfobins_entry") for s in statuses):
                return "Failed"
            return "Skipped"

          elif isinstance(first_val, dict) and "attempt" in first_val:
            # Cron‐job case
            attempts = [info.get("attempt") for info in results.values()]
            if "success" in attempts:
                return "Success"
            if any(a == "failed" for a in attempts):
                return "Failed"
            return "Skipped"

          else:
              # Fallback if neither "status" nor "attempt" appear
              return "Skipped"

        suid_state   = three_state(suid_res)
        sudo_state   = three_state(sudo_res)
        kernel_state = three_state(kernel_res)
        cron_state   = three_state(cron_res)

        overall = any(state == "Success"
              for state in (suid_state, sudo_state, kernel_state, cron_state))

        # 8) other results listing
        sudo_lines   = [f"{k}: {v.get('status')}" for k,v in sudo_res.items()]
        kernel_lines = [f"{k}: {v.get('status')}" for k,v in kernel_res.items()]
        # cron_lines   = [f"{k}: {v.get('attempt')}" for k,v in cron_res.items()]

        # 9) phase timestamps
        ctx.update({
            "timestamp_suid":   ts_for("Trying SUID exploit")   if suid_res   else "--:--:--",
            "timestamp_sudo":   ts_for("Trying SUDO exploit")   if sudo_res   else "--:--:--",
            "timestamp_kernel": ts_for("Trying kernel exploit") if kernel_res else "--:--:--",
            "timestamp_cron":   ts_for("Attempting cron payload injection") if cron_res else "--:--:--",
        })

        # 10) fill context
        ctx.update({
            "suid_vectors_indented":   indent(suid_vecs),
            "sudo_vectors_indented":   indent(sudo_vecs),
            "kernel_vectors_indented": indent(kernel_vecs),
            "cron_paths_indented":     indent(cron_jobs),

            "suid_results_indented":   indent(suid_lines),
            "sudo_results_indented":   indent(sudo_lines),
            "kernel_results_indented": indent(kernel_lines),
            "cron_results_indented":   "\n".join(cron_results_lines),

            # use three‑state labels
            "suid_success":   suid_state,
            "sudo_success":   sudo_state,
            "kernel_success": kernel_state,
            "cron_success":   cron_state,
            "overall_result": "Succeeded" if overall else "Failed",
        })

        # 11) render & write
        report = self.template.format(**ctx)
        with open(self.report_path, "w") as out:
            out.write(banner)
            out.write(report)
 
